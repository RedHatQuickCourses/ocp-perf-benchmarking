= Kubernetes-native benchmarking tools

Kubernetes-native benchmarking tools are specifically designed to measure the performance of applications and infrastructure running in containerized environments. Unlike traditional benchmarking suites, these tools understand the unique characteristics of Kubernetes, such as dynamic scaling, pod scheduling, and network overlays. They allow engineers to test real workloads under realistic conditions and observe how clusters behave under load, making them essential for both development and operations teams.

== Control plane

One widely used tool in this space is https://kube-burner.github.io/kube-burner/latest/[kube-burner], which is designed to generate configurable workloads for Kubernetes clusters. It can create pods, services, and other Kubernetes objects at scale, allowing operators to evaluate cluster behavior under high-density conditions. kube-burner is often used to test API server performance, scheduler responsiveness, and overall cluster throughput, providing metrics that help identify scaling limits and bottlenecks.

== Networking

https://github.com/cloud-bulldozer/k8s-netperf[k8s-netperf] is another Kubernetes-specific benchmarking tool focused on network performance. It supports several backends mentioned in the previous section, like https://hewlettpackard.github.io/netperf[netperf], iperf and uperf to be able to measure latency, throughput, and other network characteristics across the cluster. By running tests between pods on different nodes, k8s-netperf provides insight into how networking plugins, CNI configurations, and overlay networks affect communication performance in a cloud-native environment.

For applications exposed via HTTP or other ingress protocols, https://github.com/cloud-bulldozer/ingress-perf[ingress-perf] offers a way to benchmark the performance of Kubernetes ingress controllers. It can simulate concurrent connections, measure request latency, and generate traffic patterns similar to real-world application workloads. This helps teams understand how ingress controllers behave under stress and how configuration changes or resource constraints impact application availability and responsiveness.

== Conclusion

Overall, Kubernetes-native benchmarking tools complement traditional system benchmarks by providing visibility into cluster-level performance and cloud-native behaviors. While they are often lighter-weight and less detailed than dedicated tools like fio or iperf, they are crucial for evaluating dynamic, orchestrated environments. Subsequent chapters in this course will dive deeper into each of these tools, providing practical examples and configuration guidance.

