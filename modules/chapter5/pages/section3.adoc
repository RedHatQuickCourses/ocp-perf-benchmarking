= Hands-on with kube-burner

In this section, we will walk through a practical hands-on activity that illustrates how to use kube-burner for simulating cluster churn and measuring Control Plane responsiveness. This exercise assumes you have basic familiarity with Kubernetes and its command-line interface (kubectl).

### Prerequisites:

1. Install `kube-burner` binary or use the container image on your preferred system. Refer to the [installation guide](https://cloud-bulldozer.github.io/kube-burner/) for more details.
2. Access a running Kubernetes cluster (either local or cloud-based).
3. Ensure `kubectl` is configured and can communicate with your target Kubernetes cluster.

### Objective:
By the end of this lab activity, you should be able to:

1. Configure kube-burner jobs to simulate various control plane churn scenarios.
2. Measure and observe the control plane's responsiveness under stress.
3. Analyze test results and interpret key performance metrics.

### Step-by-step Hands-on Activity:

#### 1. Setting up kube-burner configuration files

kube-burner uses YAML configuration files to define jobs, which dictate the resources it will create, delete, or manipulate in your Kubernetes cluster. You can find example configuration files and metrics profiles in the [kube-burner examples directory](https://github.com/cloud-bulldozer/kube-burner/tree/master/examples).

Let's start by creating a simple `job.yaml` file to simulate control plane churn:

```yaml
apiVersion: kubeburner.cloud-bulldozer.io/v1alpha1
kind: Job
metadata:
  name: controlplane-churn-job
spec:
  # Specify the type of resource you want to test
  resources:
    - kind: Deployment
  # Define the number of operations for each kind of resource
  operations:
    - name: Create
      count: 10
    - name: Update
      count: 10
    - name: Delete
      count: 10
```

This configuration instructs kube-burner to create, update, and delete 10 Kubernetes Deployments. Adjust the `count` values as needed for your specific testing requirements.

#### 2. Running kube-burner job

Now that we have a configuration file ready, let's run our job against the target Kubernetes cluster:

```bash
kubectl apply -f job.yaml
```

kube-burner will start creating, updating, and deleting Deployments according to your `job.yaml` specifications. You can monitor the progress using:

```bash
kubectl -n kube-burner logs <pod-name>
```

Replace `<pod-name>` with the name of the pod generated by kube-burner for executing the job.

#### 3. Measuring Control Plane Responsiveness

While the job is running, kube-burner will collect Prometheus metrics related to control plane components (kube-apiserver, etcd, etc.). To view these metrics, set up Grafana with a predefined dashboard or use `curl` to fetch metrics directly from the Kube-API server:

```bash
kubectl top node <node-name> --format=json | jq '.containers[] | select(.name=="kube-apiserver") | .metrics'
```

Replace `<node-name>` with the name of a node in your cluster running kube-apiserver. This command extracts and displays metrics related to kube-apiserver performance.

#### 4. Analyzing Results

Once the job completes, analyze the collected Prometheus metrics to evaluate control plane responsiveness under stress. Key metrics to observe include:

- Request latency
- Error rates (5xx)
- Throughput

You can find more information on interpreting these metrics in kube-burner's documentation or through subsequent blog posts (as mentioned in the provided context).

### Conclusion

This hands-on activity has demonstrated how to configure and run kube-burner jobs for simulating control plane churn and measuring responsiveness. Through practical exercises like this, users can gain valuable insights into Kubernetes cluster performance under stress conditions. Remember to consult the comprehensive [kube-burner documentation](https://cloud-bulldozer.github.io/kube-burner/) for more in-depth guidance on using kube-burner's features and understanding test results.
