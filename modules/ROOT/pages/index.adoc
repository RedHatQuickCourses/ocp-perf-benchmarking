= OpenShift Performance Benchmarking Guide
:navtitle: Home

== Introduction

This intensive, hands-on course will teach you how to use the built-in monitoring stack and Kubernetes-native tools like kube-burner to stress-test your cluster's networking and control plane. We'll dive into establishing performance baselines, finding bottlenecks before they become problems and getting the data you need to keep your platform running smoothly and efficiently.

Duration: 4-8 hours

== What you'll learn

On completing this course, you should gain skills to proactively measure, analyze and tune an OpenShift cluster for optimal performance:

 * Articulate performance goals
 * Identify bottlenecks
 * Get familiar with Kubernetes-native benchmarking tools
 * Establish a baseline
 * Stress-test the control plane
 * Benchmark the data plane
 * Analytical and reporting abilities

== Out of scope

 * Application-level benchmarking
 * Chaos testing

== Prerequisites

This course assumes that you have the following prior experience:

 * Basic understanding of containerization (Docker, Podman) and Kubernetes/OpenShift concepts.
 * Familiarity with the Linux command line.
 * Experience with basic OpenShift administration is beneficial but not required.

== Contributors

 * José Castillo Lema <jlema@redhat.com>
 * Mohit Sheth <msheth@redhat.com>
 * Raúl Sevilla Cañavate <rsevilla@redhat.com>
 * Vishnu Challa <vchalla@redhat.com>

Special thanks to all contributors who have helped shape this resource through content creation, testing, and feedback.

== Contributing

This cookbook is actively maintained. For questions, issues, or contributions, please refer to the link:https://github.com/RedHatQuickCourses/ocp-perf-benchmarking/tree/main[project repository,window=_blank].

== License

This project is licensed under the link:https://github.com/RedHatQuickCourses/ocp-perf-benchmarking/blob/main/LICENSE[MIT License,window=_blank].

---

NOTE: This cookbook was created with assistance from AI tools to accelerate content development and improve documentation quality. However, all content is built, edited, tested, and reviewed by experienced human engineers to ensure technical accuracy and real-world applicability. We believe in transparency about our tools while maintaining human expertise and oversight at every step.