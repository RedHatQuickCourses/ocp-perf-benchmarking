= Lab Environment Setup

== Instructions to Launch Your Lab on the Red Hat Demo Platform (RHDP)

. **Log in** to the xref:#RHDP-Portal-Links[RHDP portal]
. **Search** for the catalog entry: **OpenShift Perf and Scale Benchmarking**.
. **Click** on the catalog entry in the search results.
. On the catalog page, **click** the **Order** button.
. **Fill out** the required details in the order form.
. **Review the warning** at the bottom of the form and **check the box** labeled: +
   *“I confirm that I understand the above warnings.”*
. **Click** the **Order** button to place your lab order.

=== Important Notes:
- This lab may take approximately **FIXME minutes** to become ready.
- You will receive an **email with access details** once your lab environment is ready.
- You can also **retrieve lab access** directly from the RHDP portal.

=== How to Access Your Lab via the RHDP Portal:
. On the RHDP portal, **click** on the **Services** option in the left-hand menu.
. **Select your lab** from the listings on the right-hand side of the page to view access details.

[[RHDP-Portal-Links]]
=== RHDP Portal Links
- RedHat associates: https://demo.redhat.com/[https://demo.redhat.com/,window=_blank]
- RedHat partners: https://partner.demo.redhat.com/[https://partner.demo.redhat.com/,window=_blank]

== Validate the Lab environment

Let's make sure the environment healthy and ready to continue with the training:
```bash
oc get node
oc get co    # ClusterOperators
```

=== ElasticSearch

Let's make sure the ElasticSearch instance that we need to index the benchmarking results through the course is available and responsive.

1. Get password:

    ES_PASSWORD=$(oc get secret elasticsearch-es-elastic-user -n openshift-logging -o jsonpath='{.data.elastic}' | base64 -d)

2. Get ElasticSearch route URL:

    ES_INSTANCE=$(oc get route elasticsearch-route -n openshift-logging -o jsonpath='https://{.spec.host}')


3. Check ElasticSearch endpoint health:

    curl -k -u elastic:$ES_PASSWORD $ES_INSTANCE/_cluster/health?pretty

    {
      "cluster_name" : "elasticsearch",
      "status" : "green",
      "timed_out" : false,
      "number_of_nodes" : 1,
      "number_of_data_nodes" : 1,
      "active_primary_shards" : 0,
      "active_shards" : 0,
      "relocating_shards" : 0,
      "initializing_shards" : 0,
      "unassigned_shards" : 0,
      "delayed_unassigned_shards" : 0,
      "number_of_pending_tasks" : 0,
      "number_of_in_flight_fetch" : 0,
      "task_max_waiting_in_queue_millis" : 0,
      "active_shards_percent_as_number" : 100.0
    }

=== Grafana

Let's make sure the Grafana instance that we need to visualize the benchmarking results through the course is available and responsive.

1. Get Grafana route URL:

    GRAFANA_URL=$(oc get route grafana-route -n openshift-logging -o jsonpath='https://{.spec.host}')
    echo "Grafana URL: $GRAFANA_URL"

2. Login with `admin`/`admin123`:

.Grafana login screen
image::grafana-login-1.png[width=300]

.Grafana welcome page
image::grafana-login-2.png[width=700]

==== ElasticSearch datasource

Check that the ElasticSearch datasource was properly configured and ready to use:

.Grafana ElasticSearch data source
image::grafana-es-datasource.png[width=700]

== Bring your own lab

Pre-requisites:

 * OpenShift cluster with a couple of workers (4.18 or higher)
 * ElasticSearch instance
 * Grafana Instance
 * Grafana ElasticSearch datasource

=== Vanilla Kubernetes

While they are some OpenShift specific components highlighted through the course, it should be possible to follow the course with some adjustments in vanilla Kubernetes environments, given the pre-requisites are satisfied.
